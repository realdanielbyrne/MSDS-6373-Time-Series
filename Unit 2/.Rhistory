bwplot(Race ~Age,data=mensResults)
histogram(~Age, data = mensResults)
smoothScatter(y = mensResults$Age, x = mensResults$Race,ylab = "Age (years)", xlab = "Race")
xyplot(Age ~ Race, panel = panel.lmbands, data = mensResults)
xyplot(Age ~ Race, panel = panel.lmbands, data = mensResults)
xyplot(Race~ Age, panel = panel.lmbands, data = mensResults)
xyplot(Age ~ Race, panel = panel.lmbands, data = mensResults)
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
#r = paste0("M_",r)
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
pander(head(mensResults))
plot(Age ~Race, data = mensResults,
xlab = "Age (years)", ylab = "Race")
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(mosaic)
library(gmodels)
library(knitr)
library(pander)
library(RColorBrewer)
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
#r = paste0("M_",r)
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
pander(head(mensResults))
plot(Age ~Race, data = mensResults,
xlab = "Age (years)", ylab = "Race")
stats = favstats(Age ~ Race,data=mensResults)
pander(stats)
bwplot(Race ~Age,data=mensResults)
histogram(~Age, data = mensResults)
smoothScatter(y = mensResults$Age, x = mensResults$Race,ylab = "Age (years)", xlab = "Race")
smoothScatter(y = mensResults$Age, x = as.numeric(mensResults$Race),ylab = "Age (years)", xlab = "Race")
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race")
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", title"Race Year")
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", title="Race Year")
?smoothScatter
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year")
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year v Participants Age for Mens Division")
xyplot(Age~ Race)
xyplot(Age~ Race, data = mensResults)
xyplot(Age~ Race, data = mensResults  abline = (h = 6), panel = panel.lmbands))
xyplot(Age~ Race, data = mensResults, abline = (h = 6), panel = panel.lmbands))
xyplot(Age~ Race, data = mensResults, abline = (h = 6), panel = panel.lmbands)
xyplot(Age~ Race, data = mensResults, abline = (h = 6))
xyplot(Age~ Race, data = mensResults, panel = panel.lmbands,
xyplot(Age~ Race, data = mensResults, panel = panel.lmbands)
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year v Participants Age for Mens Division")
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year v Participants Age for Mens Division")
xyplot(Age~ Race, data = mensResults, panel = panel.lmbands)
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year v Participants Age for Mens Division")
xyplot(Age ~ as.character(Race), data = mensResults, panel = panel.lmbands)
kruskal.test(Age ~ Race, data = mensResults)
wilcox.test(Age ~ Race, data = mensResults)
wilcox.test(Age ~ Race, data = mensResults,na.rm=TRUE, paired=FALSE, exact=FALSE, conf.int=TRUE)
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main="Race Year v Participants Age for Mens Division")
super
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(mosaic)
library(gmodels)
library(knitr)
library(pander)
library(RColorBrewer)
library(lattice)
splom(Age, groups=Race, data=mensResults,
panel=panel.superpose,
key=list(title="Three Cylinder Options",
points=list(pch=super.sym$pch[1:3],
col=super.sym$col[1:3]),
text=list(c("4 Cylinder","6 Cylinder","8 Cylinder"))))
splom(mensResults$Age, groups=Race, data=mensResults,
panel=panel.superpose,
key=list(title="Three Cylinder Options",
points=list(pch=super.sym$pch[1:3],
col=super.sym$col[1:3]),
text=list(c("4 Cylinder","6 Cylinder","8 Cylinder"))))
splom(mensResults$Age, groups=mensResults$Race, data=mensResults,
panel=panel.superpose,
key=list(title="Three Cylinder Options",
points=list(pch=super.sym$pch[1:3],
col=super.sym$col[1:3]),
text=list(c("4 Cylinder","6 Cylinder","8 Cylinder"))))
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
#r = paste0("M_",r)
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
pander(head(mensResults))
?as.numeric
mensResults = mensResults %>% select("Race","Name","Age")
# Load data
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
mensResults = mensResults %>% select("Race","Name","Age")
head(mensResults)
plot(Age ~Race, data = mensResults,
xlab = "Age (years)", ylab = "Race")
# Load data
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
mensResults = mensResults %>% select("Race","Name","Age")
pander(head(mensResults))
stats = favstats(Age ~ Race,data=mensResults)
pander(stats)
stats = favstats(Age ~ Race,data=mensResults)
pander(stats)
xtable(stats)
library(xtable)
stats = favstats(Age ~ Race,data=mensResults)
stats = favstats(Age ~ Race,data=mensResults)
xtable(stats)
?xtable
stats = favstats(Age ~ Race,data=mensResults)
xtable(stats, type="html")
stats = favstats(Age ~ Race,data=mensResults)
xtable(stats, type="html")
xtable(stats, type="html")
stats = favstats(Age ~ Race,data=mensResults)
print(stats, type="html")
library(car)
install.packages(car)
install.packages("car")
library(car1)
library(car)
durbinWatsonTest(lm(Age ~ Race,data=mensResults))
dw = durbinWatsonTest(lm(Age ~ Race,data=mensResults))
plot(dw)
plot(summary(dw))
summary(dw)
dw
aov1 = aov(lm(Age ~ Race, data=mensResults))
plot(aov1,which=1)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(mosaic)
library(gmodels)
library(knitr)
library(pander)
library(RColorBrewer)
library(lattice)
library(xtable)
# Load data
files = sapply(1999:2012,function(year){paste0("./MensResults",year,".csv")})
load.files = function(fileName) {
read.csv(fileName,stringsAsFactors = FALSE)
}
mensResults = do.call(rbind,lapply(files, load.files))
## Convert to number
mensResults$Age = as.numeric(mensResults$Age)
## Convert to factor
mensResults$Race = sapply(mensResults$Race,function(x) {
r = strsplit(x, " ")[[1]][1]
return (r)
})
mensResults$Race = as.factor(mensResults$Race)
mensResults = mensResults %>% select("Race","Name","Age")
pander(head(mensResults))
plot(Age ~Race, data = mensResults, ylab = "Age (years)", xlab = "Race")
stats = favstats(Age ~ Race,data=mensResults)
print(stats, type="html")
bwplot(Race ~Age,data=mensResults)
histogram(~Age, data = mensResults)
smoothScatter(y = mensResults$Age, x = as.character(mensResults$Race),ylab = "Age (years)", xlab = "Race Year", main=" Figure 4 - Smoothed Scatter of Race Year v Participant's Age")
densityplot(~Age,data=mensResults)
densityplot(~Age,groups = Race,data=mensResults)
anova(lm(Age ~ Race, data=mensResults))
summary(lm(Age~Race,data=mensResults))
results = model.tables(aov(lm(Age ~ Race,data=mensResults)))
results
aov1 = aov(lm(Age ~ Race, data=mensResults))
plot(aov1,which=1)
plot(aov1,which=2)
plot(aov1,which=3)
results
class(results)
as.array(results)
at = as.array(results)
pander (at)
results$tables
pander(results$tables)
results.tables
results = model.tables(aov(lm(Age ~ Race,data=mensResults)))
results.tables
results = model.tables(aov(lm(Age ~ Race,data=mensResults)))
results$tables
results$n
as.data.frame(results$tables)
as.matrix(results$tables)
t = as.matrix(results$tables)
t
t = as.data.frame(results$tables)
t = as.data.frame(as.matrix(results$tables))
t
results$tables$Race
class(results$tables$Race)
class(results$tables)
results$tables$Race.Race
results$tables$Race[1999]
results$tables$Race["1999"]
class(results$tables$Race["1999"])
as.data.frame.matrix(results)
as.data.frame.matrix(results$tables)
as.data.frame.matrix(results$tables$Race)
as.data.frame.matrix(results$tables)
aov(lm(Lifetime ~ Diet, data = case0501))
aov(lm(Age ~ Race,data=mensResults))
?`mtable-class`
results.results
results$n
results$n[1]
results$n[2]
results$n[1]
results$tables$Race
results$tables$Race[1]
results$tables$Race[2]
results$tables$Race[3]
results$tables$Race[1].
results$tables$Race[1][1]
results$tables$Race[1]$value
results$tables$Race[1]
class(results$tables$Race[1])
class(results$tables$Race[1][1])
results$tables$Race[1][1]
results$tables$Race[[1]]
results$tables$Race[[2]]
results$tables$Race[[1]]
results$tables$Race[[1][1]]
results$tables$Race[[0]]
results$tables$Race[[2]]
results$tables$Race[2]
results$tables$Race[1]
aov1 = aov(lm(Age ~ Race, data=mensResults))
plot(aov1,which=1,"Figure 5 - Residuals vs Fitted")
source('~/GitHub/QTW-Projects/Proj 2 Cherry Blossom/cbreaddata.r', echo=TRUE)
getAll(1999,2012)
source('~/GitHub/QTW-Projects/Proj 2 Cherry Blossom/cbreaddata.r', echo=TRUE)
getAll(1999,2012)
getAll(1999,2012)
getAll(1999,2012)
result
result <- as.data.frame( read_html(url) %>%
html_nodes(xpath='//*[@id="performances-index"]/div/table') %>%
html_table());
source('~/GitHub/QTW-Projects/Proj 2 Cherry Blossom/cbreaddata.r', echo=TRUE)
getAll(1999,2012)
install.packages("plotly")
?stack
p <- ggplot(mensResults, aes(x = values)) +
stat_density(aes(group = Race, color = Race),position="identity",geom="line")
p <- ggplotly(p)
install.packages('Cairo')
library(cairo)
library(Cairo)
library(car)
library(tswge)
data("airline")
psi.weights.wge(phi = c(1.95,-1.9),lag.max = 5)
aic5.wge(airline)
source('~/GitHub/MSDS-6373-Time-Series/Time Series Arma.R')
source('~/GitHub/MSDS-6373-Time-Series/Time Series Arma.R')
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r', echo=TRUE)
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
setwd('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
setwd('~/GitHub/MSDS-6373-Time-Series/Unit 2/')
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
librahead(Stor9Item50)
plotts.wge(Stor9Item50$sales)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
#Change to dataframe
Stor9Item50 = data.frame(Stor9Item50)
#Look at Spectral density... evidence of yearly, monthly and weekly trend?
#Yearly and Monthly are going to be tough with daily data.
parzen.wge(Stor9Item50$sales, trunc= 500)
aic5.wge(Stor9Item50_grouped$sales)
aic5.wge(Stor9Item50_grouped)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
librahead(Stor9Item50)
plotts.wge(Stor9Item50$sales)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
#Change to dataframe
Stor9Item50 = data.frame(Stor9Item50)
library(tidyverse)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
librahead(Stor9Item50)
plotts.wge(Stor9Item50$sales)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
#Change to dataframe
Stor9Item50 = data.frame(Stor9Item50)
#Look at Spectral density... evidence of yearly, monthly and weekly trend?
#Yearly and Monthly are going to be tough with daily data.
parzen.wge(Stor9Item50$sales, trunc= 500)
# Change to integers for easier sorting later.... could use other package to handle dates.
Stor9Item50$month = as.integer(Stor9Item50$month)
Stor9Item50$year = as.integer(Stor9Item50$year)
# Aggregate to get monthly sales
Stor9Item50_grouped = Stor9Item50 %>% group_by(year,month) %>% summarise(mean_sales = mean(sales))
#Note data is out of order and that is a big deal.
head(Stor9Item50_grouped)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
librahead(Stor9Item50)
plotts.wge(Stor9Item50$sales)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
head(Stor9Item50)
plotts.wge(Stor9Item50$sales)
#Break into month day and year.
Stor9Item50 = separate(Stor9Item50,col = date,into = c("month","day","year"), sep = "/")
#Change to dataframe
Stor9Item50 = data.frame(Stor9Item50)
#Look at Spectral density... evidence of yearly, monthly and weekly trend?
#Yearly and Monthly are going to be tough with daily data.
parzen.wge(Stor9Item50$sales, trunc= 500)
# Change to integers for easier sorting later.... could use other package to handle dates.
Stor9Item50$month = as.integer(Stor9Item50$month)
Stor9Item50$year = as.integer(Stor9Item50$year)
# Aggregate to get monthly sales
Stor9Item50_grouped = Stor9Item50 %>% group_by(year,month) %>% summarise(mean_sales = mean(sales))
#Note data is out of order and that is a big deal.
head(Stor9Item50_grouped)
#Order by year and month
Stor9Item50_grouped = Stor8Item1_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
# Evidence of yearly trend?  Montly trend is still tough since there are differnt number of days in a month.
parzen.wge(Stor9Item50_grouped$mean_sales)
# Change to integers for easier sorting later.... could use other package to handle dates.
Stor9Item50$month = as.integer(Stor9Item50$month)
Stor9Item50$year = as.integer(Stor9Item50$year)
# Aggregate to get monthly sales
Stor9Item50_grouped = Stor9Item50 %>% group_by(year,month) %>% summarise(mean_sales = mean(sales))
#Note data is out of order and that is a big deal.
head(Stor9Item50_grouped)
#Order by year and month
Stor9Item50_grouped = Stor8Item1_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
#Order by year and month
Stor9Item50_grouped = Stor9Item1_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
# Aggregate to get monthly sales
Stor9Item50_grouped = Stor9Item50 %>% group_by(year,month) %>% summarise(mean_sales = mean(sales))
#Order by year and month
Stor9Item50_grouped = Stor9Item50_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
#Order by year and month
Stor9Item50_grouped = Stor9Item50_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
#Order by year and month
Stor9Item50_grouped = Stor9Item50_grouped[order(Stor9Item50_grouped$year,Stor9Item50_grouped$month),]
# Evidence of yearly trend?  Montly trend is still tough since there are differnt number of days in a month.
parzen.wge(Stor9Item50_grouped$mean_sales)
# to more clearly see the annual trend
parzen.wge(Stor9Item50_grouped$mean_sales,trunc = 30)
# Shows combo of pseudo cyclic and wandering behavior.
acf(Stor9Item50_grouped$mean_sales,lag = 30)
acf(Stor9Item50_grouped$mean_sales,lag = 30)
plotts.wge(Stor9Item50_grouped$sales)
plotts.wge(Stor9Item50_grouped$mean_sales)
factor.wge(phi=c(.967))
plotts.true.wge(phi=c(-.967))
factor.wge(phi=      c(1.452,-.453,-.294,.175,.237,-.154))
plotts.true.wge(phi= c(1.452,-.453,-.294,.175,.237,-.154))
factor.wge(phi=      c(1.445,-.411,-.038,.170,.362,-.245,-.177,.213))
plotts.true.wge(phi=c(1.445,-.411,-.038,.170,.362,-.245,-.177,.213))
factor.wge(phi=c(1.384,-.359,-.309,.063,.317,-.140,-.0587,-.199,.2877));
plotts.true.wge(phi=c(1.384,-.359,-.309,.063,.317,-.140,-.0587,-.199,.2877));
findFrequencyAR2 <- function(phi1,phi2) {
acos(phi1/(2*sqrt(phi2*-1)))/(2*pi)
}
findFrequencyAR2(.2,-.8)
findFrequencyAR2(1.6,-.8)
findFrequencyAR2(-.5,-.6)
aic5.wge(Stor9Item50_grouped)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
head(Stor9Item50)
plotts.wge(Stor9Item50$sales)
aic5.wge(Stor9Item50$sales)
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
# unit 4
aic5.wge(Stor9Item50$sales)
swadelay = read.csv('swadelay.csv',header=TRUE)
aic5.wge(swadelay$arr_cancelled)
aic5.wge(airline)
source('~/GitHub/MSDS-6373-Time-Series/Unit 2/Danieltest.r')
source('~/GitHub/MSDS-6373-Time-Series/Time Series Arma.R')
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(mosaic)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
swadelay = read.csv('swadelay.csv',header=TRUE)
# Load the Data
Stor9Item50 = Walmart %>% filter(item == 50 & store == 9)#Look at and Visualize the data
aic5.wge(Stor9Item50$sales)
gen.arma.wge(n=100, phi=c(1.6,-.9), theta=.8, vara=1, plot=TRUE)
aic5.wge(swadelay$arr_cancelled)
5^2
theta1 = .8
theta2 = -.5
p1 = (-theta1 + theta1*theta2)/(1 + theta1^2 + theta2^2)
p1
library(glmnet)
install.packages("glmnet")
library(glmnet)
library(e1071)
install.packages("e1071")
factor
?factor
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(mosaic)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
swadelay = read.csv('swadelay.csv',header=TRUE)
# Load the Data
Stor8Item1 = Walmart %>% filter(item == 1 & store == 8)#Look at and Visualize the data
knitr::opts_chunk$set(echo = TRUE)
library(tswge)
library(mosaic)
# Read in the data
Walmart = read.csv('Walmart.csv',header = TRUE)
swadelay = read.csv('swadelay.csv',header=TRUE)
# Load the Data
Stor8Item1 = Walmart %>% filter(item == 1 & store == 8)#Look at and Visualize the data
aic5.wge(Stor9Item50$sales)
aic5.wge(Stor8Item1$sales)
aic5.wge(Stor8Item1$sales,p=10:15, p=0:5)
aic5.wge(Stor8Item1$sales,p=10:15, q=0:5)
theta1 = .5
theta2 = -.5
p1 = (-theta1 + theta1*theta2)/(1 + theta1^2 + theta2^2)
#p1
ans = -theta1/1+theta1^2
ans
#p1
ans = -theta1/(1+theta1^2)
ans
